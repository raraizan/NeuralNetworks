{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports and namespace configuration\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy\n",
    "\n",
    "from nn.activation_functions import *\n",
    "from nn.cost_funtions import *\n",
    "from nn import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "![Single Perceptron](http://neuralnetworksanddeeplearning.com/images/tikz0.png)\n",
    "\n",
    "$$ w_{1}x_{1} + w_{2}x_{2} + \\dots + w_{i}x_{i} > b $$\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "           w_{1} & w_{2} & \\dots & w_{i} \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "           x_{1} \\\\\n",
    "           x_{2} \\\\\n",
    "           \\vdots \\\\\n",
    "           x_{i}\n",
    "\\end{pmatrix}\n",
    "> b\n",
    "$$\n",
    "\n",
    "$$ \\vec{w} \\cdot \\vec{x} > b $$\n",
    "\n",
    "\n",
    "$$\n",
    "\\textrm{Evaluacion del perceptron} = \n",
    "\\begin{cases}\n",
    "    0 & \\textrm{if} & \\vec{w} \\cdot \\vec{x} \\leq b \\\\\n",
    "    1 & \\textrm{if} & \\vec{w} \\cdot \\vec{x} > b\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# x1, x2, x3 = 1, 2, -3\n",
    "# w1, w2, w3 = 1, -2, 2\n",
    "# b = 10\n",
    "\n",
    "# # Perceptron evaluation\n",
    "# result1 = x1 * w1 + x2 * w2 + x3 * w3 - b\n",
    "\n",
    "# # Vectorial evaluation\n",
    "# inputs = numpy.array((x1, x2, x3))\n",
    "# weights = numpy.array((w1, w2, w3))\n",
    "\n",
    "# result2 = numpy.dot(weights, inputs) - b\n",
    "\n",
    "# print(result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heaviside Function\n",
    "$$\n",
    "H(x) = \n",
    "\\begin{cases}\n",
    "    0 & \\textrm{if} & x \\leq 0 \\\\\n",
    "    1 & \\textrm{if} & x > 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = numpy.linspace(-2, 2)\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x, heaviside(x), 'k')\n",
    "ax.set_xlim(-2, 2)\n",
    "ax.set_ylim(-1.5, 2.5)\n",
    "ax.grid()\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title(\"Heaviside fintion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textrm{Evaluacion del perceptron} = \n",
    "\\begin{cases}\n",
    "    0 & \\textrm{if} & \\vec{w} \\cdot \\vec{x} - b \\leq 0 \\\\\n",
    "    1 & \\textrm{if} & \\vec{w} \\cdot \\vec{x} - b > 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$ \\textrm{Perceptron} \\to H(\\vec{w} \\cdot \\vec{x} - b) $$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Perceptron class\n",
    "class Perceptron:\n",
    "    def __init__(self, weights, bias, activation_function=None):\n",
    "        self.weights = numpy.array(weights)\n",
    "        self.bias = bias\n",
    "        self.activation_function = activation_function if activation_function else heaviside\n",
    "\n",
    "    def feedforward(self, input_vector):\n",
    "        value = self.activation_function(self.weights.dot(input_vector) - self.bias)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input space categorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for a 2D plane\n",
    "\n",
    "$$ \\vec{w} \\cdot \\vec{x} - b = w_{1}x_{1} + w_{2}x_{2} - b$$\n",
    "\n",
    "$$ w_{2}x_{2} = -w_{1}x_{1} + b$$\n",
    "\n",
    "$$ x_{2} = -\\frac{w_{1}}{w_{2}}x_{1} + \\frac{b}{w_{2}}$$\n",
    "\n",
    "$$ y = mx + b$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(x, m, b):\n",
    "    return m * x + b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# weights = numpy.array((-1, 1))\n",
    "# bias = 1\n",
    "\n",
    "# perceptron = Perceptron(weights, bias)\n",
    "\n",
    "# m = -weights[0] / weights[1]\n",
    "# b = bias / weights[1]\n",
    "\n",
    "# samples = [numpy.array((random.uniform(0, 10), random.uniform(0, 10))) for _ in range(500)]\n",
    "\n",
    "# tagged_data = [(sample, perceptron.feedforward(sample)) for sample in samples]\n",
    "# # pprint(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolution = 100\n",
    "# x = numpy.linspace(0, 10, resolution)\n",
    "# y = numpy.linspace(0, 10, resolution)\n",
    "# mapped_region = numpy.zeros((resolution, resolution))\n",
    "# for i, x_val in enumerate(x):\n",
    "#     for j, y_val in enumerate(y):\n",
    "#         sample = numpy.array((x_val, y_val))\n",
    "#         mapped_region[i][resolution - 1 - j] = perceptron.feedforward(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 5))\n",
    "\n",
    "subplots = fig.add_subplot(121), fig.add_subplot(122)\n",
    "for sub in subplots:\n",
    "    sub.set_aspect('equal')\n",
    "\n",
    "subplots[0].set_xlim(0, 10)\n",
    "subplots[0].set_ylim(0, 10)\n",
    "subplots[1]\n",
    "\n",
    "for sample, tag in tagged_data:\n",
    "    if tag:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'blue'\n",
    "    subplots[0].plot(sample[0], sample[1], color=color, marker = 'o', markersize=2)\n",
    "\n",
    "\n",
    "subplots[0].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), m, b), 'k--')\n",
    "subplots[0].set_title('Weights = ({1}, {2})'.format(*weights, bias))\n",
    "\n",
    "subplots[1].imshow(mapped_region, cmap='gray')\n",
    "subplots[1].set_title('[0, 10]x[0, 10] mapped to [0, 1]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The inverse problem\n",
    "Adjust a perceptron to a data set\n",
    "### Cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mod this to play with the cost\n",
    "perceptron = Perceptron((0.2, 1), 6)\n",
    "\n",
    "perceptron_m, perceptron_b = - perceptron.weights[0] / perceptron.weights[1], perceptron.bias / perceptron.weights[1]\n",
    "print(perceptron_m, perceptron_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "m = -1\n",
    "b = 10\n",
    "\n",
    "dataset = []\n",
    "for _ in range(1000):\n",
    "    x, y = random.uniform(0, 10), random.uniform(0, 10)\n",
    "    if y <= m * x + b:\n",
    "        value = 0.0\n",
    "    else:\n",
    "        value = 1.0\n",
    "    dataset.append((numpy.array((x, y)), value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "subplots = fig.add_subplot(131), fig.add_subplot(132), fig.add_subplot(133)\n",
    "\n",
    "for sample, tag in dataset:\n",
    "    color = 'red' if tag else 'blue'\n",
    "    subplots[0].plot(sample[0], sample[1], color=color, marker='o', markersize=2)\n",
    "subplots[0].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), m, b), linestyle='--', label='dataset division')\n",
    "\n",
    "for sample, _ in dataset:\n",
    "    tag = perceptron.feedforward(sample)\n",
    "    color = 'red' if tag else 'blue'\n",
    "    subplots[1].plot(sample[0], sample[1], color=color, marker='o', markersize=2)\n",
    "subplots[1].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), perceptron_m, perceptron_b), linestyle='--', label='perceptron division')\n",
    "\n",
    "for sample, data_tag in dataset:\n",
    "    predicted_tag = perceptron.feedforward(sample)\n",
    "    color = 'red' if (data_tag and predicted_tag) else 'green' if (data_tag or predicted_tag) else 'blue'\n",
    "    subplots[2].plot(sample[0], sample[1], color=color, marker='o', markersize=2)\n",
    "subplots[2].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), perceptron_m, perceptron_b), linestyle='--', label='perceptron division')\n",
    "subplots[2].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), m, b), linestyle='--', label='dataset division')\n",
    "\n",
    "for sub in subplots:\n",
    "    sub.set_aspect('equal')\n",
    "    sub.set_xlim(0, 10)\n",
    "    sub.set_ylim(0, 10)\n",
    "    sub.grid()\n",
    "    sub.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def square_error(tagged_dataset, evaluation_funtion):\n",
    "    data_length = len(tagged_dataset)\n",
    "    error = 0\n",
    "    for sample, dataset_tag in tagged_dataset:\n",
    "        predicted_tag = evaluation_funtion(sample)\n",
    "        error += (dataset_tag - predicted_tag)**2\n",
    "    return error / data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "square_error(dataset, perceptron.feedforward)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def train(self, dataset, subsets=10, max_iters=100, eps=1e-16, cost_function=None):\n",
    "\n",
    "    cost_funtion = cost_function if cost_function else square_error\n",
    "\n",
    "    counter = 0\n",
    "    epsilon = 1e-16\n",
    "\n",
    "    self.error_history = []\n",
    "    self.params_history = []\n",
    "    best_params = self.weights, self.bias\n",
    "    best_error = cost_funtion(dataset, self.feedforward)\n",
    "    print(\"initial error: {}\".format(best_error))\n",
    "\n",
    "    while best_error >= eps and counter < max_iters:\n",
    "        # Generate a set of variations from the initial params\n",
    "        param_variations = [\n",
    "            (\n",
    "                numpy.array(\n",
    "                    tuple([random.gauss(weight, best_error) for weight in best_params[0]]),\n",
    "                ),\n",
    "                random.gauss(best_params[1], best_error),\n",
    "            ) for _ in range(10)]\n",
    "\n",
    "        # Evaluate all and find the best\n",
    "        for i, params in enumerate(param_variations):\n",
    "            self.weights, self.bias = params\n",
    "\n",
    "            current_error = cost_funtion(dataset, self.feedforward)\n",
    "            if  current_error <= best_error:\n",
    "                best_error = current_error\n",
    "                best_params = params\n",
    "\n",
    "        self.error_history.append(best_error)\n",
    "        self.params_history.append(best_params)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    final_error = square_error(dataset, self.feedforward)\n",
    "    print(\"final error: {}\".format(final_error))\n",
    "\n",
    "    return self.error_history, self.params_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_history, params_history = perceptron.train(dataset)\n",
    "\n",
    "perceptron_m, perceptron_b = - perceptron.weights[0] / perceptron.weights[1], perceptron.bias / perceptron.weights[1]\n",
    "print(perceptron_m, perceptron_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line_history = [(-weights[0] / weights[1], bias / weights[1]) for weights, bias in params_history]\n",
    "x = numpy.linspace(0, 10)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 4))\n",
    "ax, bx = fig.add_subplot(121), fig.add_subplot(122)\n",
    "ax.set_xlim(0, 10), ax.set_ylim(0, 10), ax.set_aspect('equal'), ax.grid()\n",
    "bx.set_title(\"Cost of the perceptron\"), bx.set_xlim(0, len(line_history)), bx.set_ylim(0, max(error_history) * 1.1), bx.grid()\n",
    "\n",
    "ax.plot(x, line(x, m, b), '--', label=\"Dataset division\")\n",
    "for sample, data_tag in dataset:\n",
    "    color = 'red' if data_tag else 'blue'\n",
    "    ax.plot(sample[0], sample[1], color=color, marker='o', markersize=2)\n",
    "\n",
    "ax.set_title('Perceptron adjustment for iteration 0')\n",
    "line1, = ax.plot(x, line_history[0][0] * x + line_history[0][1], 'k', label=\"Perceptron division\")\n",
    "line2, = bx.plot([0], error_history[0])\n",
    "lines = [line1, line2]\n",
    "\n",
    "def init():\n",
    "    lines[0].set_data([], [])\n",
    "    lines[1].set_data([], [])\n",
    "    return lines,\n",
    "\n",
    "def animate(i):\n",
    "    x = numpy.linspace(0, 10)\n",
    "    y = line_history[i][0] * x + line_history[i][1]\n",
    "    print(x)\n",
    "    lines[0].set_data(x, y)\n",
    "    ax.set_title('Perceptron adjustment for iteration {}'.format(i))\n",
    "    lines[1].set_data(range(i), error_history[:i])\n",
    "    return lines,\n",
    "\n",
    "ax.legend(loc='upper right')\n",
    "anim = FuncAnimation(fig, animate, init_func=init, frames=len(line_history), interval=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a non linear dataset\n",
    "\n",
    "non_linear_datasets = [[],[],[]]\n",
    "\n",
    "for _ in range(1000):\n",
    "    x, y = random.uniform(-2, 2), random.uniform(-2, 2)\n",
    "    if x**2 + y**2 <= 1:\n",
    "        value = 1.0\n",
    "    else:\n",
    "        value = 0.0\n",
    "    non_linear_datasets[0].append((numpy.array((x, y)), value))\n",
    "    \n",
    "for _ in range(1000):\n",
    "    x, y = random.uniform(-numpy.pi, numpy.pi), random.uniform(-2, 2)\n",
    "    if y > numpy.sin(x):\n",
    "        value = 1.0\n",
    "    else:\n",
    "        value = 0.0\n",
    "    non_linear_datasets[1].append((numpy.array((x, y)), value))\n",
    "\n",
    "for _ in range(1000):\n",
    "    x, y = random.uniform(-2, 2), random.uniform(-1, 3)\n",
    "    if y > x**2:\n",
    "        value = 1.0\n",
    "    else:\n",
    "        value = 0.0\n",
    "    non_linear_datasets[2].append((numpy.array((x, y)), value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 3))\n",
    "subplots = fig.add_subplot(131), fig.add_subplot(132), fig.add_subplot(133)\n",
    "\n",
    "for i, dataset in enumerate(non_linear_datasets):\n",
    "    subplots[i].grid()\n",
    "    for sample, tag in dataset:\n",
    "        color = 'red' if tag else 'blue'\n",
    "        subplots[i].plot(sample[0], sample[1], color=color, marker='o', markersize=2)\n",
    "    subplots[i].set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
