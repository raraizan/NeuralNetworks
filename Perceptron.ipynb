{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports and namespace configuration\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "from nn.activation_functions import *\n",
    "from nn.cost_funtions import *\n",
    "\n",
    "from nn import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "![Single Perceptron](http://neuralnetworksanddeeplearning.com/images/tikz0.png)\n",
    "\n",
    "$$ w_{1}x_{1} + w_{2}x_{2} + \\dots + w_{i}x_{i} > b $$\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "           w_{1} & w_{2} & \\dots & w_{i} \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "           x_{1} \\\\\n",
    "           x_{2} \\\\\n",
    "           \\vdots \\\\\n",
    "           x_{i}\n",
    "\\end{pmatrix}\n",
    "> b\n",
    "$$\n",
    "\n",
    "$$ \\vec{w} \\cdot \\vec{x} > b $$\n",
    "\n",
    "\n",
    "$$\n",
    "\\textrm{Evaluacion del perceptron} = \n",
    "\\begin{cases}\n",
    "    0 & \\textrm{if} & \\vec{w} \\cdot \\vec{x} \\leq b \\\\\n",
    "    1 & \\textrm{if} & \\vec{w} \\cdot \\vec{x} > b\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3 = 1, 2, 3\n",
    "w1, w2, w3 = 5, 87, 8\n",
    "b = 10\n",
    "\n",
    "# Perceptron evaluation\n",
    "result1 = x1 * w1 + x2 * w2 + x3 * w3 - b\n",
    "\n",
    "# Vectorial evaluation\n",
    "inputs = numpy.array((x1, x2, x3))\n",
    "weights = numpy.array((w1, w2, w3))\n",
    "\n",
    "result2 = numpy.dot(weights, inputs) - b\n",
    "\n",
    "print(result1, result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heaviside Function\n",
    "$$\n",
    "H(x) = \n",
    "\\begin{cases}\n",
    "    0 & \\textrm{if} & x \\leq 0 \\\\\n",
    "    1 & \\textrm{if} & x > 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = numpy.linspace(-2, 2)\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(x, heaviside(x), 'k')\n",
    "ax.set_xlim(-2, 2)\n",
    "ax.set_ylim(-1.5, 2.5)\n",
    "ax.grid()\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title(\"Heaviside fintion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textrm{Evaluacion del perceptron} = \n",
    "\\begin{cases}\n",
    "    0 & \\textrm{if} & \\vec{w} \\cdot \\vec{x} - b \\leq 0 \\\\\n",
    "    1 & \\textrm{if} & \\vec{w} \\cdot \\vec{x} - b > 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$ \\textrm{Perceptron} \\to H(\\vec{w} \\cdot \\vec{x} - b) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input space categorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for a 2D plane\n",
    "\n",
    "$$ \\vec{w} \\cdot \\vec{x} - b = w_{1}x_{1} + w_{2}x_{2} - b$$\n",
    "\n",
    "$$ w_{2}x_{2} = -w_{1}x_{1} + b$$\n",
    "\n",
    "$$ x_{2} = -\\frac{w_{1}}{w_{2}}x_{1} + \\frac{b}{w_{2}}$$\n",
    "\n",
    "$$ y = mx + b$$\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Perceptron class\n",
    "class Perceptron:\n",
    "    def __init__(self, weights, bias, activation_function=None):\n",
    "        self.weights = numpy.array(weights)\n",
    "        self.bias = bias\n",
    "        self.activation_function = activation_function if activation_function else heaviside\n",
    "\n",
    "    def feedforward(self, input_vector):\n",
    "        value = self.activation_function(self.weights.dot(input_vector) - self.bias)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(x, m, b):\n",
    "    return m * x + b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights = numpy.array((-1, 1))\n",
    "bias = 1\n",
    "\n",
    "perceptron = Perceptron(weights, bias)\n",
    "\n",
    "m = -weights[0] / weights[1]\n",
    "b = bias / weights[1]\n",
    "\n",
    "samples = [numpy.array((random.uniform(0, 10), random.uniform(0, 10))) for _ in range(500)]\n",
    "\n",
    "tagged_data = [(sample, perceptron.feedforward(sample)) for sample in samples]\n",
    "# pprint(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 100\n",
    "x = numpy.linspace(0, 10, resolution)\n",
    "y = numpy.linspace(0, 10, resolution)\n",
    "mapped_region = numpy.zeros((resolution, resolution))\n",
    "for i, x_val in enumerate(x):\n",
    "    for j, y_val in enumerate(y):\n",
    "        sample = numpy.array((x_val, y_val))\n",
    "        mapped_region[i][resolution - 1 - j] = perceptron.feedforward(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "subplots = fig.add_subplot(121), fig.add_subplot(122)\n",
    "for sub in subplots:\n",
    "    sub.set_aspect('equal')\n",
    "\n",
    "subplots[0].set_xlim(0, 10)\n",
    "subplots[0].set_ylim(0, 10)\n",
    "subplots[1]\n",
    "\n",
    "for sample, tag in tagged_data:\n",
    "    if tag:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'blue'\n",
    "    subplots[0].plot(sample[0], sample[1], color=color, marker = 'o', markersize=2)\n",
    "\n",
    "\n",
    "subplots[0].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), m, b), 'k--')\n",
    "subplots[0].set_title('Weights ={1}, {2}'.format(*weights, bias))\n",
    "\n",
    "subplots[1].imshow(mapped_region, cmap='gray')\n",
    "subplots[1].set_title('[0, 10]x[0, 10] mapped to [0, 1]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron((0.2, 1), 6)\n",
    "\n",
    "perceptron_m, perceptron_b = - perceptron.weights[0] / perceptron.weights[1], perceptron.bias / perceptron.weights[1]\n",
    "print(perceptron_m, perceptron_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "m = -1\n",
    "b = 10\n",
    "\n",
    "dataset = []\n",
    "for _ in range(1000):\n",
    "    x, y = random.uniform(0, 10), random.uniform(0, 10)\n",
    "    if y <= m * x + b:\n",
    "        value = 0.0\n",
    "    else:\n",
    "        value = 1.0\n",
    "    dataset.append((numpy.array((x, y)), value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17,5))\n",
    "subplots = fig.add_subplot(131), fig.add_subplot(132), fig.add_subplot(133)\n",
    "\n",
    "for sample, tag in dataset:\n",
    "    color = 'red' if tag else 'blue'\n",
    "    subplots[0].plot(sample[0], sample[1], color=color, marker='o', markersize=2)\n",
    "subplots[0].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), m, b), linestyle='--', label='dataset division')\n",
    "\n",
    "for sample, _ in dataset:\n",
    "    tag = perceptron.feedforward(sample)\n",
    "    color = 'red' if tag else 'blue'\n",
    "    subplots[1].plot(sample[0], sample[1], color=color, marker='o', markersize=2)\n",
    "subplots[1].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), perceptron_m, perceptron_b), linestyle='--', label='perceptron division')\n",
    "\n",
    "for sample, data_tag in dataset:\n",
    "    predicted_tag = perceptron.feedforward(sample)\n",
    "    color = 'red' if (data_tag and predicted_tag) else 'green' if (data_tag or predicted_tag) else 'blue'\n",
    "    subplots[2].plot(sample[0], sample[1], color=color, marker='o', markersize=2)\n",
    "subplots[2].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), perceptron_m, perceptron_b), linestyle='--', label='perceptron division')\n",
    "subplots[2].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), m, b), linestyle='--', label='perceptron division')\n",
    "\n",
    "for sub in subplots:\n",
    "    sub.set_aspect('equal')\n",
    "    sub.set_xlim(0, 10)\n",
    "    sub.set_ylim(0, 10)\n",
    "    sub.grid()\n",
    "    sub.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def square_error(tagged_dataset, perceptron):\n",
    "    data_length = len(tagged_dataset)\n",
    "    error = 0\n",
    "    for sample, dataset_tag in tagged_dataset:\n",
    "        predicted_tag = perceptron.feedforward(sample)\n",
    "        error += (dataset_tag - predicted_tag)**2\n",
    "    return error / data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "square_error(dataset, perceptron.feedforward)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Perceptron class\n",
    "class Perceptron:\n",
    "    def __init__(self, weights, bias, activation_function=None):\n",
    "        self.weights = numpy.array(weights)\n",
    "        self.bias = bias\n",
    "        self.activation_function = activation_function if activation_function else heaviside\n",
    "        \n",
    "    def __str__(self):\n",
    "        print(\"Perceptron initialized with:\")\n",
    "        print(\"{} weights, {}\".format(len(self.weights), self.weights))\n",
    "        print(\"{} as bias\".format(self.bias))\n",
    "\n",
    "    def feedforward(self, input_vector):\n",
    "        value = self.activation_function(self.weights.dot(input_vector) - self.bias)\n",
    "        return value\n",
    "    \n",
    "    def train(self, dataset, subsets=10, max_iters=100, eps=1e-16, cost_function=None):\n",
    "        \n",
    "        cost_funtion = cost_function if cost_function else square_error\n",
    "\n",
    "        counter = 0\n",
    "        epsilon = 1e-16\n",
    "\n",
    "        self.error_history = []\n",
    "        self.params_history = []\n",
    "        best_params = self.weights, self.bias\n",
    "        best_error = cost_funtion(dataset, self.feedforward)\n",
    "        print(\"initial error: {}\".format(best_error))\n",
    "\n",
    "        while best_error >= eps and counter < max_iters:\n",
    "            # Generate a set of variations from the initial params\n",
    "            param_variations = [\n",
    "                (\n",
    "                    numpy.array(\n",
    "                        tuple([random.gauss(weight, best_error) for weight in best_params[0]]),\n",
    "                    ),\n",
    "                    random.gauss(best_params[1], best_error),\n",
    "                ) for _ in range(10)]\n",
    "\n",
    "            # Evaluate all and find the best\n",
    "            for i, params in enumerate(param_variations):\n",
    "                self.weights, self.bias = params\n",
    "\n",
    "                current_error = cost_funtion(dataset, self.feedforward)\n",
    "                if  current_error <= best_error:\n",
    "                    best_error = current_error\n",
    "                    best_params = params\n",
    "            \n",
    "            self.error_history.append(best_error)\n",
    "            self.params_history.append(best_params)\n",
    "\n",
    "            counter += 1\n",
    "        \n",
    "        final_error = square_error(dataset, self.feedforward)\n",
    "        print(\"final error: {}\".format(final_error))\n",
    "\n",
    "        return self.error_history, self.params_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_history, params_history = perceptron.train(dataset)\n",
    "\n",
    "perceptron_m, perceptron_b = - perceptron.weights[0] / perceptron.weights[1], perceptron.bias / perceptron.weights[1]\n",
    "print(perceptron_m, perceptron_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11,5))\n",
    "subplots = fig.add_subplot(121), fig.add_subplot(122)\n",
    "\n",
    "# Plot the points\n",
    "for sample, data_tag in dataset:\n",
    "    predicted_tag = perceptron.feedforward(sample)\n",
    "    color = 'red' if (data_tag and predicted_tag) else 'green' if (data_tag or predicted_tag) else 'blue'\n",
    "    subplots[0].plot(sample[0], sample[1], color=color, marker='o', markersize=2)\n",
    "\n",
    "subplots[0].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), perceptron_m, perceptron_b), linestyle='--', label='trained perceptron division')\n",
    "subplots[0].plot(numpy.linspace(0, 10), line(numpy.linspace(0, 10), m, b), linestyle='--', label='perceptron division')\n",
    "\n",
    "subplots[1].plot(error_history)\n",
    "\n",
    "subplots[0].set_xlim(0, 10)\n",
    "subplots[0].set_ylim(0, 10)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a non linear dataset\n",
    "\n",
    "non_linear_datasets = [[],[],[]]\n",
    "\n",
    "for _ in range(1000):\n",
    "    x, y = random.uniform(-2, 2), random.uniform(-2, 2)\n",
    "    if x**2 + y**2 <= 1:\n",
    "        value = 1.0\n",
    "    else:\n",
    "        value = 0.0\n",
    "    non_linear_datasets[0].append((numpy.array((x, y)), value))\n",
    "    \n",
    "for _ in range(1000):\n",
    "    x, y = random.uniform(-numpy.pi, numpy.pi), random.uniform(-2, 2)\n",
    "    if y > numpy.sin(x):\n",
    "        value = 1.0\n",
    "    else:\n",
    "        value = 0.0\n",
    "    non_linear_datasets[1].append((numpy.array((x, y)), value))\n",
    "\n",
    "for _ in range(1000):\n",
    "    x, y = random.uniform(-2, 2), random.uniform(-1, 3)\n",
    "    if y > x**2:\n",
    "        value = 1.0\n",
    "    else:\n",
    "        value = 0.0\n",
    "    non_linear_datasets[2].append((numpy.array((x, y)), value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17,5))\n",
    "subplots = fig.add_subplot(131), fig.add_subplot(132), fig.add_subplot(133)\n",
    "\n",
    "for i, dataset in enumerate(non_linear_datasets):\n",
    "    subplots[i].grid()\n",
    "    for sample, tag in dataset:\n",
    "        color = 'red' if tag else 'blue'\n",
    "        subplots[i].plot(sample[0], sample[1], color=color, marker='o', markersize=2)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
